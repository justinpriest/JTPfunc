---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
library(JTPfunc)
library(dplyr)
library(tibble)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# Package JTPfunc



A random collection of miscellaneous functions. 

### Installation

You can install the development version of JTPfunc from [GitHub](https://github.com/) with:

``` r 
# install.packages("devtools")
devtools::install_github("justinpriest/JTPfunc")
```

## Example Functions

There are many unique functions contained here, many with esoteric applications 
to ADF&G data.  


### Function `statweek()`

To calculate the statistical week (Sunday-Saturday), use function `statweek()`
on a date object to return the stat week: 
```{r statweekdemo}
statweek(as.Date("2021-07-01"))
```


<hr>
<br>

### Function `theme_crisp()`

One applicable extension is a ggplot theme called with `theme_crisp()`:
```{r exampleplot, fig.height = 3, fig.width = 7, warning = FALSE, message = FALSE}
library(JTPfunc)
library(ggplot2)
ggplot(mtcars, aes(x = wt, y = mpg, color = wt)) + geom_point() + theme_crisp()
```


<hr>
<br>

### Function `duplicaterows()`

For certain types of date (e.g., age summaries from the scale database)
the data are exported in an already summarized manner. That is,
all fish of the same date, species, sex, length, etc. are combined 
into a single row.  
If we wish to run statistics on these data, it is helpful to have each
row be its own observation.  
Our example data look like: 

```{r cohodataimp, include = FALSE}
coholengthdata <- tibble::tribble(
                    ~Species, ~Sex, ~Length, ~Count,
                      "Coho",  "M",    621L,     1L,
                      "Coho",  "F",    497L,     2L,
                      "Coho",  "M",    557L,     3L,
                      "Coho",  "F",    563L,     1L
                    )


```

```{r cohodatasumm}
coholengthdata 
```

To add new rows to these data, we use function `duplicaterows()`, specifying 
which row is the number of times to repeat. We can see that the row
with the two 497 mm female coho is repeated twice while the row with 
three 557 mm male coho is repeated 3 times:  
```{r cohodatafxn}
duplicaterows(dataframename = coholengthdata, 
              duplicatecolname = "Count")

```

<hr>
<br>

### Function `count_pct()`

A common request is to determine the proportion of observations for each group 
of data. Assuming that each row is an individual, we can calculate a quick 
summary using `count_pct()` like so: 
```{r countpctdemo}
count_pct(iris %>%
           group_by(Species))
```


<hr>
<br>

### Function `addrowconditional()`
For the following example, we'll use hypothetical rockfish catch data.  
In some historical datasets, catches were not identified to a specific species 
but rather to species aggregates. For example, species code 168 refers to 
unspecified demersal shelf rockfishes while species code 140 is red rockfishes. 

```{r loaddata, include = FALSE}
rockfishcatch <- tibble::tribble(
  ~Year, ~Location, ~Species, ~Catch,
  2010L,   "Outer",     140L,    12L,
  2010L,   "Inner",     140L,    33L,
  2010L,  "Middle",     140L,    19L,
  2010L,   "Outer",     168L,    33L,
  2010L,   "Inner",     168L,    27L,
  2010L,  "Middle",     168L,    24L,
  2010L,   "Outer",     110L,    33L,
  2010L,   "Inner",     110L,    27L,
  2010L,  "Middle",     110L,    24L,
  2011L,   "Outer",     140L,    12L,
  2011L,   "Inner",     140L,    33L,
  2011L,  "Middle",     140L,    19L,
  2011L,   "Outer",     168L,    33L,
  2011L,   "Inner",     168L,    27L,
  2011L,  "Middle",     168L,    24L 
)
rockfishcatch <- rockfishcatch %>%
  mutate(Location = as.factor(Location))

```

```{r showdata}
head(rockfishcatch)
```

For these data, the total catch of the species aggregates (species 140 and 168) 
was composed of several species. For this reason, these species may 
require adding additional rows so that the total catch may be apportioned. 
In our example, we repeat all rows of species 168 three times, and 
repeat rows of species 140 two times, then sort by year and species:
```{r addrowconddemo}
addrowconditional(rockfishcatch, criteriacolumn = Species,
                   repeatcount1 = 3, repeatcount2 = 2,
                   criteria1 = 168, criteria2 = 140,
                   sort1 = Year, sort2 = Species)
```


<hr>
<br>

### Function `impute_global()`
Dealing with missing data requires imputing the missing values based on a 
relationship between known variables. The `impute_global` function will create 
an imputed value for the use case of multiple rivers, multiple years, and a 
single (escapement) count. Many biologists use an Excel addin ("Missfill") to 
impute across the river (columns) / year (rows) matrix. This function works on 
"long" format data such as downloaded from OceanAK and imputes across all 
available years/rivers. This uses an iterative approach, following Blick. 
This function can be easily modified to auto-create a named dataframe 
(argument "outputname"). Make sure that all NAs are present (a missing row is 
NOT same as a row with an NA). 


For example, consider this dataset of 3 streams and 4 years, containing 2 NAs. 
```{r imputedemodata, include = FALSE}
streamcounts <- tibble::tribble(
  ~Year,              ~Stream, ~Count,
  2022L,      "Berners River",     NA,
  2023L,      "Berners River",   200L,
  2024L,      "Berners River",   150L,
  2025L,      "Berners River",   300L,
  2022L,      "Niukluk River",  1000L,
  2023L,      "Niukluk River",   900L,
  2024L,      "Niukluk River",   800L,
  2025L,      "Niukluk River",  1200L,
  2022L, "Resurrection Creek",   150L,
  2023L, "Resurrection Creek",     NA,
  2024L, "Resurrection Creek",   140L,
  2025L, "Resurrection Creek",   300L
  )
```

```{r imputedemodata_show}
streamcounts 
```

To impute the missing values, we run `impute_global()`:

```{r imputedemofunc}
impute_global(streamcounts, Year_column = "Year", StreamName_column = "Stream",
              count_column = "Count")
```



There are actually several impute functions in this package, each imputing for 
specific use cases:  
`impute_global()`: Impute all available data and years.  
`impute_local()`: 10-yr Localized Imputation. This takes a dataframe with NA values 
and imputes missing data. This algorithm uses "local" imputation: only 5 years 
before and after impute a missing value, i.e., only using the preceding 5 years 
and following 5 years.  
`impute_local_improved()`: 10-yr Localized Imputation, improved. This algorithm 
uses the `impute_local()` implementation, however it adds a rule for the first 10 
years to use the 10 next years (10-year minimum).  
`impute_cohodefault()`: Specific to the SEAK Coho Research program, this imputes 
1987-2000 first, then each year is imputed after that, building on itself (i.e., 
imputed values from 2001 inform the imputation in 2002).  
